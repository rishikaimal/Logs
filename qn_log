#!/bin/sh

# Wait for ping
targetHost="203.0.113.121"
while ! ping -c 1 -W 1 "$targetHost" >/dev/null; do
    sleep 5
done
# Check connection to Rudder
cloud_conn="/mnt/flash/sw-config.json"
while [ "$(jq -r '.wizard.done' "$cloud_conn")" == "false" ]; do
    sleep 5
done

# Initializations
REGISTRY_FILE="/mnt/flash/system/.registry"
tempEX="/tmp/tempEX"
tempDT="/tmp/tempDT"
tempLOG="/tmp/tempLOG"
tempOUT="/tmp/tempOut.txt"
output="/tmp/output.txt"
newlogs="/tmp/new_logs.txt"
permLogs="/mnt/flash/external/persistent/switch_logs"
OID1=".1.3.6.1.4.1.89.82.2.9.1.2" # date time
OID2=".1.3.6.1.4.1.89.82.2.9.1.6" # logs
OID3=".1.3.6.1.4.1.89.82.2.9.1.7" # extra logs
commString="public"
SR_NO=$(grep '0x1004' "$REGISTRY_FILE" 2>/dev/null | cut -d'=' -f2 | tr -d ' .<>*\\/\t')
intervalFile="/mnt/flash/external/persistent/qnlog_interval"
    if [ -e "$intervalFile" ] && [ -s "$intervalFile" ]; then
        interval=$(cat "$intervalFile")
    else
        interval=60
    fi

# Snmpwalk into Files
walksnmp() {
    filename="$1"
    snmpwalk -v2c -c "$commString" "$targetHost" "$OID1" | awk -F "STRING: " '{gsub(/"/,""); print $2}' >"$tempDT"
    snmpwalk -v2c -c "$commString" "$targetHost" "$OID2" | awk -F "STRING: " '{gsub(/"/,""); print $2}' | awk 'BEGIN { RS="\n\n" } { gsub(/\n\n/," "); print $0 }' >"$tempLOG"
    snmpwalk -v2c -c "$commString" "$targetHost" "$OID3" | awk -F "STRING: " '{gsub(/"/,""); print $2}' | awk 'BEGIN { RS="\n\n" } { gsub(/\n\n/," "); print $0 }' >"$tempEX"
    awk '{ if ((getline dt < ARGV[2]) > 0 && (getline ex < ARGV[3]) > 0) print $0 dt ex }' "$tempDT" "$tempLOG" "$tempEX" >"$filename"
    cd /tmp/
    rm "$tempDT" "$tempLOG" "$tempEX"
}

# Publish to MQTT
publish() {
    data="$1"

        while true; do
            exec /usr/bin/publish "$data" &
            wait $!
            if [ $? -eq 0 ]; then
                break
            else
                sleep 1
            fi
        done
}

# Json function
generate_json() {
    JSONDATA=$(
        jq --null-input \
            --arg sr_no "$SR_NO" \
            --arg data "$1" \
            '{"sr_no": $sr_no, "data": $data}'
    )
    echo "$JSONDATA"
}

# Send Initial Logs
walksnmp "$tempOUT"
FIRST_LOGS=$(cat "$tempOUT")
FIRST_DATA=$(generate_json "$FIRST_LOGS")
reboot=$(generate_json "SWITCH REBOOTED")
if [ "$(jq -r '.wizard.miyagi_cloud_conn' "$cloud_conn")" == "true" ]; then
    publish "$reboot"
    publish "$FIRST_DATA"
    echo "[$(date "+%d-%b-%Y %H:%M:%S")] Initial Logs sent."
fi

# Store in permanent memory
temp_file="/tmp/temp_file"
touch "$temp_file"
printf "============================== SWITCH REBOOTED ==============================\n" | cat - "$permLogs" >"$temp_file"
mv "$temp_file" "$permLogs"

if [ -s "$permLogs" ]; then
    touch "$temp_file"
    cat "$tempOUT" "$permLogs" >>"$temp_file"
    mv "$temp_file" "$permLogs"
else
    cp "$tempOUT" "$permLogs"
fi

# Loop to keep checking for new logs
while true; do

    walksnmp "$output"
    grep -Fxv -f "$tempOUT" "$output" | awk '{print $0}' >"$newlogs"
    if [ -s "$newlogs" ]; then
        LOGS=$(cat "$newlogs")
        MYDATA=$(generate_json "$LOGS")
        if [ "$(jq -r '.wizard.miyagi_cloud_conn' "$cloud_conn")" == "true" ]; then
            publish "$MYDATA"
            echo "[$(date "+%d-%b-%Y %H:%M:%S")] Updated Logs sent."
        fi
    fi

    cd /tmp/
    cp "$output" "$tempOUT"
    # Store in permanent memory
    cat "$newlogs" >"$temp_file"
    cat "$permLogs" >>"$temp_file"
    mv "$temp_file" "$permLogs"
 
    # Keep permanent entries restricted to specific number.
        head -n 2000 "$permLogs" > "/tmp/file.tmp"                         
        mv "/tmp/file.tmp" "$permLogs"

    sleep $interval
done
